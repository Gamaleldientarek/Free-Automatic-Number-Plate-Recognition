{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PN1cAxdvd61e"
      },
      "source": [
        "<div align=\"center\">\n",
        "\n",
        "  <a href=\"https://ultralytics.com/yolo\" target=\"_blank\">\n",
        "    <img width=\"1024\", src=\"https://raw.githubusercontent.com/ultralytics/assets/main/yolov8/banner-yolov8.png\"></a>\n",
        "\n",
        "  [ä¸­æ–‡](https://docs.ultralytics.com/zh/) | [í•œêµ­ì–´](https://docs.ultralytics.com/ko/) | [æ—¥æœ¬èª](https://docs.ultralytics.com/ja/) | [Ğ ÑƒÑÑĞºĞ¸Ğ¹](https://docs.ultralytics.com/ru/) | [Deutsch](https://docs.ultralytics.com/de/) | [FranÃ§ais](https://docs.ultralytics.com/fr/) | [EspaÃ±ol](https://docs.ultralytics.com/es/) | [PortuguÃªs](https://docs.ultralytics.com/pt/) | [TÃ¼rkÃ§e](https://docs.ultralytics.com/tr/) | [Tiáº¿ng Viá»‡t](https://docs.ultralytics.com/vi/) | [Ø§Ù„Ø¹Ø±Ø¨ÙŠØ©](https://docs.ultralytics.com/ar/)\n",
        "\n",
        "  <a href=\"https://github.com/ultralytics/ultralytics/actions/workflows/ci.yml\"><img src=\"https://github.com/ultralytics/ultralytics/actions/workflows/ci.yml/badge.svg\" alt=\"Ultralytics CI\"></a>\n",
        "  <a href=\"https://colab.research.google.com/github/ultralytics/notebooks/blob/main/notebooks/how-to-use-ultralytics-yolo-with-openai-for-number-plate-recognition.ipynb\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"></a>\n",
        "  \n",
        "  <a href=\"https://ultralytics.com/discord\"><img alt=\"Discord\" src=\"https://img.shields.io/discord/1089800235347353640?logo=discord&logoColor=white&label=Discord&color=blue\"></a>\n",
        "  <a href=\"https://community.ultralytics.com\"><img alt=\"Ultralytics Forums\" src=\"https://img.shields.io/discourse/users?server=https%3A%2F%2Fcommunity.ultralytics.com&logo=discourse&label=Forums&color=blue\"></a>\n",
        "  <a href=\"https://reddit.com/r/ultralytics\"><img alt=\"Ultralytics Reddit\" src=\"https://img.shields.io/reddit/subreddit-subscribers/ultralytics?style=flat&logo=reddit&logoColor=white&label=Reddit&color=blue\"></a>\n",
        "  \n",
        "  Welcome to the ANPR with Ultralytics YOLO11 notebook! <a href=\"https://github.com/ultralytics/ultralytics\">YOLO11</a> is the latest version of the YOLO (You Only Look Once) AI models developed by <a href=\"https://ultralytics.com\">Ultralytics</a>. We hope that the resources in this notebook will help you get the most out of YOLO11. Please browse the YOLO11 <a href=\"https://docs.ultralytics.com/\">Docs</a> for details, raise an issue on <a href=\"https://github.com/ultralytics/ultralytics\">GitHub</a> for support, and join our <a href=\"https://ultralytics.com/discord\">Discord</a> community for questions and discussions!</div>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "64B195mdjxQd"
      },
      "source": [
        "# Automatic Number Plate Recognition using Ultralytics YOLO11 + OpenAI `gpt-4o-mini`\n",
        "\n",
        "This notebook provides a comprehensive guide to implementing automatic number plate recognition (ANPR) using the YOLO11 model in combination with `gpt-4o-mini`.\n",
        "\n",
        "## What is Automatic Number Plate Recognition (ANPR)?\n",
        "Automatic number plate recognition is a technology designed to identify and extract vehicle number plate information from images or videos. By leveraging the powerful capabilities of Ultralytics YOLO11 for object detection and OpenAI `gpt-4o-mini` for text recognition, ANPR becomes an efficient solution for automating vehicle identification tasks.\n",
        "\n",
        "## Why Use YOLO11 + GPT-4o-Mini for ANPR?\n",
        "\n",
        "- Accurate Detection: YOLO11â€™s object detection capabilities ensure precise localization of license plates in various conditions, such as low light or high-speed movement.\n",
        "\n",
        "- Seamless Text Recognition: With `gpt-4o-mini`, extracted license plate regions are processed to recognize alphanumeric text accurately, even with variations in font, angle, or clarity.\n",
        "\n",
        "- Real-Time Processing: The integration allows for real-time vehicle monitoring, making it ideal for applications in traffic management, parking systems, and security surveillance.ğŸš—"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o68Sg1oOeZm2"
      },
      "source": [
        "### Setup\n",
        "\n",
        "pip install `ultralytics` and [dependencies](https://github.com/ultralytics/ultralytics/blob/main/pyproject.toml) and check software and hardware.\n",
        "\n",
        "[![PyPI - Version](https://img.shields.io/pypi/v/ultralytics?logo=pypi&logoColor=white)](https://pypi.org/project/ultralytics/) [![Downloads](https://static.pepy.tech/badge/ultralytics)](https://www.pepy.tech/projects/ultralytics) [![PyPI - Python Version](https://img.shields.io/pypi/pyversions/ultralytics?logo=python&logoColor=gold)](https://pypi.org/project/ultralytics/)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9dSwz_uOReMI",
        "outputId": "b8e52e8c-5801-4406-c2c4-01a85cf9f932"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting ultralytics\n",
            "  Downloading ultralytics-8.3.145-py3-none-any.whl.metadata (37 kB)\n",
            "Requirement already satisfied: numpy>=1.23.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (2.0.2)\n",
            "Requirement already satisfied: matplotlib>=3.3.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (3.10.0)\n",
            "Requirement already satisfied: opencv-python>=4.6.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (4.11.0.86)\n",
            "Requirement already satisfied: pillow>=7.1.2 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (11.2.1)\n",
            "Requirement already satisfied: pyyaml>=5.3.1 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (6.0.2)\n",
            "Requirement already satisfied: requests>=2.23.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (2.32.3)\n",
            "Requirement already satisfied: scipy>=1.4.1 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (1.15.3)\n",
            "Requirement already satisfied: torch>=1.8.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (2.6.0+cu124)\n",
            "Requirement already satisfied: torchvision>=0.9.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (0.21.0+cu124)\n",
            "Requirement already satisfied: tqdm>=4.64.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (4.67.1)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from ultralytics) (5.9.5)\n",
            "Requirement already satisfied: py-cpuinfo in /usr/local/lib/python3.11/dist-packages (from ultralytics) (9.0.0)\n",
            "Requirement already satisfied: pandas>=1.1.4 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (2.2.2)\n",
            "Collecting ultralytics-thop>=2.0.0 (from ultralytics)\n",
            "  Downloading ultralytics_thop-2.0.14-py3-none-any.whl.metadata (9.4 kB)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (1.3.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (4.58.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (1.4.8)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (24.2)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (3.2.3)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.1.4->ultralytics) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.1.4->ultralytics) (2025.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.23.0->ultralytics) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.23.0->ultralytics) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.23.0->ultralytics) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.23.0->ultralytics) (2025.4.26)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (3.18.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (4.13.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (2025.3.2)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch>=1.8.0->ultralytics)\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch>=1.8.0->ultralytics)\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch>=1.8.0->ultralytics)\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch>=1.8.0->ultralytics)\n",
            "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch>=1.8.0->ultralytics)\n",
            "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch>=1.8.0->ultralytics)\n",
            "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.5.147 (from torch>=1.8.0->ultralytics)\n",
            "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch>=1.8.0->ultralytics)\n",
            "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch>=1.8.0->ultralytics)\n",
            "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (12.4.127)\n",
            "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch>=1.8.0->ultralytics)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=1.8.0->ultralytics) (1.3.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.7->matplotlib>=3.3.0->ultralytics) (1.17.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=1.8.0->ultralytics) (3.0.2)\n",
            "Downloading ultralytics-8.3.145-py3-none-any.whl (1.0 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m57.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m104.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m72.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m62.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m13.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m7.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m84.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading ultralytics_thop-2.0.14-py3-none-any.whl (26 kB)\n",
            "Installing collected packages: nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, ultralytics-thop, ultralytics\n",
            "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
            "    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n",
            "    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.6.82\n",
            "    Uninstalling nvidia-curand-cu12-10.3.6.82:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n",
            "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
            "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n",
            "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n",
            "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n",
            "  Attempting uninstall: nvidia-cudnn-cu12\n",
            "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
            "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
            "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n"
          ]
        }
      ],
      "source": [
        "!pip install ultralytics\n",
        "\n",
        "import base64\n",
        "\n",
        "import cv2\n",
        "import ultralytics\n",
        "from openai import OpenAI\n",
        "from ultralytics import YOLO\n",
        "from ultralytics.utils.downloads import safe_download\n",
        "from ultralytics.utils.plotting import Annotator, colors\n",
        "\n",
        "ultralytics.checks()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IIZw8IJOk3Lb"
      },
      "source": [
        "### Download the Video and Model File\n",
        "\n",
        "Download the sample video weâ€™ll use for processing. If you prefer to use your own video file, downloading the sample is not necessary.  \n",
        "\n",
        "âœ… Weâ€™ll download a license plate detection model `anpr-demo-model.pt` trained on a small dataset, designed to detect license plates in the sample video. You are welcome to use your own custom models as well.  \n",
        "\n",
        "âš ï¸ Note: This license plate detection model `anpr-demo-model.pt` is intended solely for proof of concept (POC) purposes and may only work with `anpr-demo-video.mp4`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wkajxl6nlObU"
      },
      "outputs": [],
      "source": [
        "# download the sample video file\n",
        "safe_download(\"https://github.com/ultralytics/assets/releases/download/v0.0.0/anpr-demo-video.mp4\")\n",
        "\n",
        "# download the sample model file\n",
        "safe_download(\"https://github.com/ultralytics/assets/releases/download/v0.0.0/anpr-demo-model.pt\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qpKaC03TZDlr"
      },
      "source": [
        "### Read the Video and Model File | Or Upload your Own\n",
        "\n",
        "You can either read the video file directly or stream content from an RTSP (Real-Time Streaming Protocol) source, offering flexible video input options to meet your requirements.\n",
        "\n",
        "âœ… By default, we will use the demo video `anpr-demo-video.mp4` downloaded in the previous step. Additionally, weâ€™ll set up the video writer to manage the output video processing.\n",
        "\n",
        "âœ… The model `anpr-demo-model.pt` will also be initialized in memory to handle the processing. You can also use your own model for license plate detection."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2daZuXgaZDFH"
      },
      "outputs": [],
      "source": [
        "cap = cv2.VideoCapture(\"/content/anpr-demo-video.mp4\")\n",
        "assert cap.isOpened(), \"Error reading video file\"\n",
        "\n",
        "# Video writer\n",
        "w, h, fps = (int(cap.get(x)) for x in (cv2.CAP_PROP_FRAME_WIDTH, cv2.CAP_PROP_FRAME_HEIGHT, cv2.CAP_PROP_FPS))\n",
        "video_writer = cv2.VideoWriter(\"anpr-output.avi\", cv2.VideoWriter_fourcc(*\"mp4v\"), fps, (w, h))\n",
        "\n",
        "# Load the Ultralytics YOLO license plate detection model\n",
        "model = YOLO(\"/content/anpr-demo-model.pt\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e0QOXawB2-Zw"
      },
      "source": [
        "<img align=\"left\" src=\"https://github.com/user-attachments/assets/101152c3-25ba-48a7-9916-c32c3be5857e\" height=\"640\">"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Install EasyOCR (Free Alternative) to OpenAI or Gemini"
      ],
      "metadata": {
        "id": "FWb820jEUvtB"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Cx-u59HQdu2o"
      },
      "outputs": [],
      "source": [
        "# Install EasyOCR\n",
        "!pip install easyocr==1.7.1\n",
        "\n",
        "# Import EasyOCR\n",
        "import easyocr\n",
        "import cv2\n",
        "from ultralytics import YOLO\n",
        "from ultralytics.utils.plotting import Annotator, colors\n",
        "\n",
        "# Initialize EasyOCR Reader\n",
        "reader = easyocr.Reader(['en']) # You can add more languages if needed\n",
        "\n",
        "# Define padding\n",
        "padding = 10\n",
        "\n",
        "# Assuming the necessary variables from previous cells are available:\n",
        "# cap = cv2.VideoCapture(...)\n",
        "# video_writer = cv2.VideoWriter(...)\n",
        "# model = YOLO(...)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m7VkxQ2aeg7k"
      },
      "source": [
        "### Process Video Frames\n",
        "\n",
        "In this step, we will process video frames to detect objects, crop regions with padding, and extract license plate text using an OpenAI model. Here's how it works:\n",
        "\n",
        "âœ… Frames are read using OpenCV, and objects are detected using the YOLO11 model.\n",
        "Bounding boxes are adjusted with padding to crop regions of interest while ensuring proper boundaries.\n",
        "\n",
        "âœ… Cropped regions are encoded in base64 and sent to the `extract_text` function, which uses OpenAIâ€™s model to retrieve license plate text.\n",
        "\n",
        "âœ… The extracted text is added as a label to the bounding box on the video frame.\n",
        "\n",
        "âœ… Processed frames are saved to an output video file."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Ensure cap, video_writer, and model are defined from previous cells before running this block\n",
        "\n",
        "while cap.isOpened():\n",
        "    success, im0 = cap.read()\n",
        "\n",
        "    if not success:\n",
        "        break\n",
        "\n",
        "    results = model.predict(im0)[0].boxes\n",
        "    boxes = results.xyxy.cpu()\n",
        "    clss = results.cls.cpu()\n",
        "\n",
        "    # Initialize Annotator inside the loop as im0 changes per frame\n",
        "    ann = Annotator(im0, line_width=3)\n",
        "\n",
        "    for cls, box in zip(clss, boxes):\n",
        "        height, width, _ = im0.shape  # Get the dimensions of the original image\n",
        "\n",
        "        # Calculate padded coordinates\n",
        "        x1 = max(int(box[0]) - padding, 0)\n",
        "        y1 = max(int(box[1]) - padding, 0)\n",
        "        x2 = min(int(box[2]) + padding, width)\n",
        "        y2 = min(int(box[3]) + padding, height)\n",
        "\n",
        "        # Crop the object with padding\n",
        "        # Check if the cropped region is valid before processing\n",
        "        if y2 > y1 and x2 > x1:\n",
        "            cropped_im = im0[y1:y2, x1:x2]\n",
        "\n",
        "            # Use EasyOCR to read text from the cropped image\n",
        "            results_easyocr = reader.readtext(cropped_im)\n",
        "\n",
        "            # Extract the recognized text\n",
        "            recognized_text = \"\"\n",
        "            for result in results_easyocr:\n",
        "                recognized_text += result[1] + \" \" # result[1] is the recognized text\n",
        "\n",
        "            print(f\"Extracted text: {recognized_text.strip()}\")\n",
        "\n",
        "            ann.box_label(box, label=str(recognized_text.strip()), color=colors(cls, True))  # Draw the bounding boxes\n",
        "        else:\n",
        "            # Handle cases where padding results in an invalid crop region\n",
        "            print(f\"Invalid crop region for box: {box}\")\n",
        "            recognized_text = \"N/A\" # Or some other indicator\n",
        "\n",
        "            ann.box_label(box, label=recognized_text, color=colors(cls, True)) # Draw bounding box without text or with N/A\n",
        "\n",
        "    video_writer.write(im0)  # Write the processed video frame\n",
        "\n",
        "cap.release()  # Release the video capture\n",
        "video_writer.release()  # Release the video writer"
      ],
      "metadata": {
        "id": "V32TQTlmU7zB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8eac44c3-5ac9-4f89-91d2-e981e1fbbdd5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 640x384 3 plates, 493.9ms\n",
            "Speed: 17.2ms preprocess, 493.9ms inference, 886.7ms postprocess per image at shape (1, 3, 640, 384)\n",
            "Extracted text: 5379MX-L\n",
            "Extracted text: \n",
            "Extracted text: \n",
            "\n",
            "0: 640x384 3 plates, 40.1ms\n",
            "Speed: 5.9ms preprocess, 40.1ms inference, 2.3ms postprocess per image at shape (1, 3, 640, 384)\n",
            "Extracted text: 5379MX-L\n",
            "Extracted text: \n",
            "Extracted text: \n",
            "\n",
            "0: 640x384 4 plates, 32.5ms\n",
            "Speed: 6.9ms preprocess, 32.5ms inference, 2.2ms postprocess per image at shape (1, 3, 640, 384)\n",
            "Extracted text: 5379MX-L\n",
            "Extracted text: \n",
            "Extracted text: \n",
            "Extracted text: \n",
            "\n",
            "0: 640x384 4 plates, 45.9ms\n",
            "Speed: 5.4ms preprocess, 45.9ms inference, 7.9ms postprocess per image at shape (1, 3, 640, 384)\n",
            "Extracted text: 5379MX-B\n",
            "Extracted text: \n",
            "Extracted text: \n",
            "Extracted text: \n",
            "\n",
            "0: 640x384 4 plates, 55.1ms\n",
            "Speed: 8.4ms preprocess, 55.1ms inference, 2.4ms postprocess per image at shape (1, 3, 640, 384)\n",
            "Extracted text: 5379MX-B\n",
            "Extracted text: \n",
            "Extracted text: \n",
            "Extracted text: \n",
            "\n",
            "0: 640x384 4 plates, 54.9ms\n",
            "Speed: 4.4ms preprocess, 54.9ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 384)\n",
            "Extracted text: Btty\n",
            "Extracted text: 5379MX-Z\n",
            "Extracted text: \n",
            "Extracted text: \n",
            "\n",
            "0: 640x384 4 plates, 33.4ms\n",
            "Speed: 4.6ms preprocess, 33.4ms inference, 8.5ms postprocess per image at shape (1, 3, 640, 384)\n",
            "Extracted text: uutJ\n",
            "Extracted text: 5379MX-B\n",
            "Extracted text: \n",
            "Extracted text: \n",
            "\n",
            "0: 640x384 4 plates, 68.4ms\n",
            "Speed: 8.7ms preprocess, 68.4ms inference, 2.3ms postprocess per image at shape (1, 3, 640, 384)\n",
            "Extracted text: 5379MX-Z\n",
            "Extracted text: \n",
            "Extracted text: \n",
            "Extracted text: \n",
            "\n",
            "0: 640x384 4 plates, 64.7ms\n",
            "Speed: 7.9ms preprocess, 64.7ms inference, 12.9ms postprocess per image at shape (1, 3, 640, 384)\n",
            "Extracted text: E30\n",
            "Extracted text: 5379MX-L\n",
            "Extracted text: \n",
            "Extracted text: \n",
            "\n",
            "0: 640x384 6 plates, 49.6ms\n",
            "Speed: 6.6ms preprocess, 49.6ms inference, 7.3ms postprocess per image at shape (1, 3, 640, 384)\n",
            "Extracted text: 5379MX-L\n",
            "Extracted text: Atouty\n",
            "Extracted text: E307\n",
            "Extracted text: \n",
            "Extracted text: \n",
            "Extracted text: E3Q\n",
            "\n",
            "0: 640x384 5 plates, 33.1ms\n",
            "Speed: 10.2ms preprocess, 33.1ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 384)\n",
            "Extracted text: 5379MX-Z\n",
            "Extracted text: 306\n",
            "Extracted text: 3277Fee\n",
            "Extracted text: \n",
            "Extracted text: \n",
            "\n",
            "0: 640x384 6 plates, 42.6ms\n",
            "Speed: 3.7ms preprocess, 42.6ms inference, 2.6ms postprocess per image at shape (1, 3, 640, 384)\n",
            "Extracted text: 5379MX-Z\n",
            "Extracted text: 306\n",
            "Extracted text: \n",
            "Extracted text: \n",
            "Extracted text: E3oE\n",
            "Extracted text: LILIJ\n",
            "\n",
            "0: 640x384 5 plates, 42.5ms\n",
            "Speed: 3.5ms preprocess, 42.5ms inference, 12.3ms postprocess per image at shape (1, 3, 640, 384)\n",
            "Extracted text: 5379MX-Z\n",
            "Extracted text: E306\"\n",
            "Extracted text: \n",
            "Extracted text: abalty\n",
            "Extracted text: Lee Btr\n",
            "\n",
            "0: 640x384 4 plates, 42.4ms\n",
            "Speed: 6.1ms preprocess, 42.4ms inference, 2.5ms postprocess per image at shape (1, 3, 640, 384)\n",
            "Extracted text: 5379MX-Z\n",
            "Extracted text: E3066\n",
            "Extracted text: \n",
            "Extracted text: \n",
            "\n",
            "0: 640x384 4 plates, 39.9ms\n",
            "Speed: 13.0ms preprocess, 39.9ms inference, 2.2ms postprocess per image at shape (1, 3, 640, 384)\n",
            "Extracted text: E3066\n",
            "Extracted text: 5379MXZ\n",
            "Extracted text: Edoora\n",
            "Extracted text: \n",
            "\n",
            "0: 640x384 4 plates, 50.6ms\n",
            "Speed: 3.5ms preprocess, 50.6ms inference, 5.4ms postprocess per image at shape (1, 3, 640, 384)\n",
            "Extracted text: 5379MX-Z\n",
            "Extracted text: E3066\"\n",
            "Extracted text: \n",
            "Extracted text: \n",
            "\n",
            "0: 640x384 4 plates, 28.1ms\n",
            "Speed: 3.5ms preprocess, 28.1ms inference, 4.3ms postprocess per image at shape (1, 3, 640, 384)\n",
            "Extracted text: E30660\n",
            "Extracted text: 5379MX-L\n",
            "Extracted text: elJ\n",
            "Extracted text: \n",
            "\n",
            "0: 640x384 4 plates, 33.1ms\n",
            "Speed: 3.6ms preprocess, 33.1ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 384)\n",
            "Extracted text: 5379MX-Z\n",
            "Extracted text: E3o661\n",
            "Extracted text: \n",
            "Extracted text: Helr]\n",
            "\n",
            "0: 640x384 4 plates, 39.2ms\n",
            "Speed: 6.4ms preprocess, 39.2ms inference, 4.4ms postprocess per image at shape (1, 3, 640, 384)\n",
            "Extracted text: Ezo66M\"\n",
            "Extracted text: BY 5379MX-L\n",
            "Extracted text: \n",
            "Extracted text: Eeenr]\n",
            "\n",
            "0: 640x384 4 plates, 69.1ms\n",
            "Speed: 7.6ms preprocess, 69.1ms inference, 7.1ms postprocess per image at shape (1, 3, 640, 384)\n",
            "Extracted text: 5379MX-Z\n",
            "Extracted text: 3066MF\n",
            "Extracted text: \n",
            "Extracted text: \n",
            "\n",
            "0: 640x384 3 plates, 33.6ms\n",
            "Speed: 8.2ms preprocess, 33.6ms inference, 4.2ms postprocess per image at shape (1, 3, 640, 384)\n",
            "Extracted text: 3066MP\n",
            "Extracted text: 5379MX-Z\n",
            "Extracted text: \n",
            "\n",
            "0: 640x384 4 plates, 56.4ms\n",
            "Speed: 11.8ms preprocess, 56.4ms inference, 5.5ms postprocess per image at shape (1, 3, 640, 384)\n",
            "Extracted text: BY 5379MX-L\n",
            "Extracted text: 3066MP-\n",
            "Extracted text: \n",
            "Extracted text: \n",
            "\n",
            "0: 640x384 5 plates, 55.3ms\n",
            "Speed: 9.7ms preprocess, 55.3ms inference, 2.2ms postprocess per image at shape (1, 3, 640, 384)\n",
            "Extracted text: 3066MP-\n",
            "Extracted text: 5379MX-Z\n",
            "Extracted text: \n",
            "Extracted text: \n",
            "Extracted text: \n",
            "\n",
            "0: 640x384 4 plates, 56.6ms\n",
            "Speed: 3.6ms preprocess, 56.6ms inference, 4.2ms postprocess per image at shape (1, 3, 640, 384)\n",
            "Extracted text: 5379MX-L\n",
            "Extracted text: 3066MP-L\n",
            "Extracted text: \n",
            "Extracted text: \n",
            "\n",
            "0: 640x384 4 plates, 35.5ms\n",
            "Speed: 5.5ms preprocess, 35.5ms inference, 8.8ms postprocess per image at shape (1, 3, 640, 384)\n",
            "Extracted text: 5379MX-L\n",
            "Extracted text: 3066MP-4\n",
            "Extracted text: \n",
            "Extracted text: \n",
            "\n",
            "0: 640x384 4 plates, 42.9ms\n",
            "Speed: 4.6ms preprocess, 42.9ms inference, 2.8ms postprocess per image at shape (1, 3, 640, 384)\n",
            "Extracted text: BlY 5379MX-\n",
            "Extracted text: E3066MP-4\n",
            "Extracted text: \n",
            "Extracted text: \n",
            "\n",
            "0: 640x384 4 plates, 53.6ms\n",
            "Speed: 3.5ms preprocess, 53.6ms inference, 2.2ms postprocess per image at shape (1, 3, 640, 384)\n",
            "Extracted text: BY 5379MX\n",
            "Extracted text: \n",
            "Extracted text: 3066MP-4\n",
            "Extracted text: \n",
            "\n",
            "0: 640x384 4 plates, 39.0ms\n",
            "Speed: 7.1ms preprocess, 39.0ms inference, 7.2ms postprocess per image at shape (1, 3, 640, 384)\n",
            "Extracted text: BY 5379M\n",
            "Extracted text: \n",
            "Extracted text: 3066MP-4\n",
            "Extracted text: \n",
            "\n",
            "0: 640x384 4 plates, 73.8ms\n",
            "Speed: 3.6ms preprocess, 73.8ms inference, 5.9ms postprocess per image at shape (1, 3, 640, 384)\n",
            "Extracted text: BY 5379\n",
            "Extracted text: \n",
            "Extracted text: 3066MP-4\n",
            "Extracted text: \n",
            "\n",
            "0: 640x384 4 plates, 79.8ms\n",
            "Speed: 12.3ms preprocess, 79.8ms inference, 15.0ms postprocess per image at shape (1, 3, 640, 384)\n",
            "Extracted text: BV 5372\n",
            "Extracted text: 3066MP-4\n",
            "Extracted text: \n",
            "Extracted text: \n",
            "\n",
            "0: 640x384 5 plates, 124.2ms\n",
            "Speed: 11.4ms preprocess, 124.2ms inference, 5.5ms postprocess per image at shape (1, 3, 640, 384)\n",
            "Extracted text: BY 537\n",
            "Extracted text: 3066MP-4\n",
            "Extracted text: \n",
            "Extracted text: \n",
            "Extracted text: \n",
            "\n",
            "0: 640x384 5 plates, 61.1ms\n",
            "Speed: 4.6ms preprocess, 61.1ms inference, 2.5ms postprocess per image at shape (1, 3, 640, 384)\n",
            "Extracted text: BY 5\n",
            "Extracted text: 3066MP-4\n",
            "Extracted text: \n",
            "Extracted text: \n",
            "Extracted text: \n",
            "\n",
            "0: 640x384 4 plates, 61.9ms\n",
            "Speed: 7.0ms preprocess, 61.9ms inference, 25.4ms postprocess per image at shape (1, 3, 640, 384)\n",
            "Extracted text: BY\n",
            "Extracted text: 3066MP-4\n",
            "Extracted text: \n",
            "Extracted text: \n",
            "\n",
            "0: 640x384 4 plates, 48.7ms\n",
            "Speed: 3.6ms preprocess, 48.7ms inference, 2.2ms postprocess per image at shape (1, 3, 640, 384)\n",
            "Extracted text: 3066MP-4\n",
            "Extracted text: \n",
            "Extracted text: \n",
            "Extracted text: \n",
            "\n",
            "0: 640x384 4 plates, 43.1ms\n",
            "Speed: 4.2ms preprocess, 43.1ms inference, 3.7ms postprocess per image at shape (1, 3, 640, 384)\n",
            "Extracted text: 3066MP-4\n",
            "Extracted text: \n",
            "Extracted text: \n",
            "Extracted text: \n",
            "\n",
            "0: 640x384 4 plates, 15.6ms\n",
            "Speed: 3.4ms preprocess, 15.6ms inference, 2.4ms postprocess per image at shape (1, 3, 640, 384)\n",
            "Extracted text: 3066MP-4\n",
            "Extracted text: \n",
            "Extracted text: \n",
            "Extracted text: \n",
            "\n",
            "0: 640x384 4 plates, 22.1ms\n",
            "Speed: 3.5ms preprocess, 22.1ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 384)\n",
            "Extracted text: 3066MP-4\n",
            "Extracted text: \n",
            "Extracted text: \n",
            "Extracted text: \n",
            "\n",
            "0: 640x384 4 plates, 18.6ms\n",
            "Speed: 3.4ms preprocess, 18.6ms inference, 9.0ms postprocess per image at shape (1, 3, 640, 384)\n",
            "Extracted text: 3066MP-4\n",
            "Extracted text: \n",
            "Extracted text: \n",
            "Extracted text: \n",
            "\n",
            "0: 640x384 3 plates, 28.7ms\n",
            "Speed: 3.4ms preprocess, 28.7ms inference, 4.1ms postprocess per image at shape (1, 3, 640, 384)\n",
            "Extracted text: 3066MP-4\n",
            "Extracted text: \n",
            "Extracted text: \n",
            "\n",
            "0: 640x384 3 plates, 20.1ms\n",
            "Speed: 3.5ms preprocess, 20.1ms inference, 2.4ms postprocess per image at shape (1, 3, 640, 384)\n",
            "Extracted text: 3066MP-4\n",
            "Extracted text: \n",
            "Extracted text: \n",
            "\n",
            "0: 640x384 2 plates, 24.8ms\n",
            "Speed: 3.4ms preprocess, 24.8ms inference, 5.2ms postprocess per image at shape (1, 3, 640, 384)\n",
            "Extracted text: 3066MP-4\n",
            "Extracted text: \n",
            "\n",
            "0: 640x384 3 plates, 13.3ms\n",
            "Speed: 6.0ms preprocess, 13.3ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 384)\n",
            "Extracted text: 3066MP-4\n",
            "Extracted text: \n",
            "Extracted text: \n",
            "\n",
            "0: 640x384 3 plates, 34.1ms\n",
            "Speed: 4.3ms preprocess, 34.1ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 384)\n",
            "Extracted text: 3066MP-4\n",
            "Extracted text: \n",
            "Extracted text: \n",
            "\n",
            "0: 640x384 2 plates, 27.7ms\n",
            "Speed: 3.4ms preprocess, 27.7ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 384)\n",
            "Extracted text: 3066MP-4\n",
            "Extracted text: \n",
            "\n",
            "0: 640x384 2 plates, 22.6ms\n",
            "Speed: 3.4ms preprocess, 22.6ms inference, 2.3ms postprocess per image at shape (1, 3, 640, 384)\n",
            "Extracted text: 3066MP-4\n",
            "Extracted text: \n",
            "\n",
            "0: 640x384 2 plates, 26.3ms\n",
            "Speed: 3.6ms preprocess, 26.3ms inference, 2.3ms postprocess per image at shape (1, 3, 640, 384)\n",
            "Extracted text: 3066MP-4\n",
            "Extracted text: \n",
            "\n",
            "0: 640x384 2 plates, 32.5ms\n",
            "Speed: 3.5ms preprocess, 32.5ms inference, 2.2ms postprocess per image at shape (1, 3, 640, 384)\n",
            "Extracted text: 3066MP-4\n",
            "Extracted text: \n",
            "\n",
            "0: 640x384 2 plates, 39.8ms\n",
            "Speed: 3.6ms preprocess, 39.8ms inference, 2.3ms postprocess per image at shape (1, 3, 640, 384)\n",
            "Extracted text: 3066MP-4\n",
            "Extracted text: \n",
            "\n",
            "0: 640x384 2 plates, 24.0ms\n",
            "Speed: 3.6ms preprocess, 24.0ms inference, 2.2ms postprocess per image at shape (1, 3, 640, 384)\n",
            "Extracted text: 3066MP-4\n",
            "Extracted text: \n",
            "\n",
            "0: 640x384 2 plates, 49.8ms\n",
            "Speed: 3.9ms preprocess, 49.8ms inference, 15.6ms postprocess per image at shape (1, 3, 640, 384)\n",
            "Extracted text: 3066MP-4\n",
            "Extracted text: \n",
            "\n",
            "0: 640x384 2 plates, 40.3ms\n",
            "Speed: 6.7ms preprocess, 40.3ms inference, 2.2ms postprocess per image at shape (1, 3, 640, 384)\n",
            "Extracted text: 3066MP-4\n",
            "Extracted text: \n",
            "\n",
            "0: 640x384 2 plates, 13.0ms\n",
            "Speed: 3.5ms preprocess, 13.0ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 384)\n",
            "Extracted text: 3066MP-4\n",
            "Extracted text: \n",
            "\n",
            "0: 640x384 2 plates, 12.6ms\n",
            "Speed: 3.7ms preprocess, 12.6ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 384)\n",
            "Extracted text: 3066MP-4\n",
            "Extracted text: \n",
            "\n",
            "0: 640x384 2 plates, 11.7ms\n",
            "Speed: 6.1ms preprocess, 11.7ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 384)\n",
            "Extracted text: 3066MP-4\n",
            "Extracted text: \n",
            "\n",
            "0: 640x384 2 plates, 13.3ms\n",
            "Speed: 3.5ms preprocess, 13.3ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 384)\n",
            "Extracted text: 3066MP-4\n",
            "Extracted text: \n",
            "\n",
            "0: 640x384 2 plates, 15.1ms\n",
            "Speed: 4.1ms preprocess, 15.1ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 384)\n",
            "Extracted text: 3066MP-4\n",
            "Extracted text: \n",
            "\n",
            "0: 640x384 1 plate, 10.9ms\n",
            "Speed: 3.5ms preprocess, 10.9ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 384)\n",
            "Extracted text: 3066MP-4\n",
            "\n",
            "0: 640x384 3 plates, 12.3ms\n",
            "Speed: 4.1ms preprocess, 12.3ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 384)\n",
            "Extracted text: 3066MP-4\n",
            "Extracted text: \n",
            "Extracted text: \n",
            "\n",
            "0: 640x384 2 plates, 13.0ms\n",
            "Speed: 3.5ms preprocess, 13.0ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 384)\n",
            "Extracted text: 3066MP-4\n",
            "Extracted text: \n",
            "\n",
            "0: 640x384 1 plate, 10.5ms\n",
            "Speed: 3.3ms preprocess, 10.5ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 384)\n",
            "Extracted text: 3066MP-4\n",
            "\n",
            "0: 640x384 1 plate, 13.4ms\n",
            "Speed: 3.1ms preprocess, 13.4ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 384)\n",
            "Extracted text: 3066MP-4\n",
            "\n",
            "0: 640x384 2 plates, 13.1ms\n",
            "Speed: 3.6ms preprocess, 13.1ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 384)\n",
            "Extracted text: 3066MP-4\n",
            "Extracted text: \n",
            "\n",
            "0: 640x384 1 plate, 10.3ms\n",
            "Speed: 3.3ms preprocess, 10.3ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 384)\n",
            "Extracted text: 3066MP-4\n",
            "\n",
            "0: 640x384 2 plates, 11.1ms\n",
            "Speed: 3.3ms preprocess, 11.1ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 384)\n",
            "Extracted text: 3066MP-4\n",
            "Extracted text: \n",
            "\n",
            "0: 640x384 2 plates, 13.3ms\n",
            "Speed: 3.2ms preprocess, 13.3ms inference, 2.7ms postprocess per image at shape (1, 3, 640, 384)\n",
            "Extracted text: 3066MP-4\n",
            "Extracted text: \n",
            "\n",
            "0: 640x384 2 plates, 14.6ms\n",
            "Speed: 3.3ms preprocess, 14.6ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 384)\n",
            "Extracted text: 3066MP-4\n",
            "Extracted text: \n",
            "\n",
            "0: 640x384 2 plates, 10.6ms\n",
            "Speed: 3.4ms preprocess, 10.6ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 384)\n",
            "Extracted text: 3066MP-4\n",
            "Extracted text: \n",
            "\n",
            "0: 640x384 2 plates, 11.1ms\n",
            "Speed: 3.5ms preprocess, 11.1ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 384)\n",
            "Extracted text: 3066MP-4\n",
            "Extracted text: \n",
            "\n",
            "0: 640x384 2 plates, 13.5ms\n",
            "Speed: 3.4ms preprocess, 13.5ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 384)\n",
            "Extracted text: 3066MP-4\n",
            "Extracted text: \n",
            "\n",
            "0: 640x384 1 plate, 13.8ms\n",
            "Speed: 4.8ms preprocess, 13.8ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 384)\n",
            "Extracted text: 3066MP-4\n",
            "\n",
            "0: 640x384 2 plates, 12.4ms\n",
            "Speed: 3.7ms preprocess, 12.4ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 384)\n",
            "Extracted text: 3066MP-4\n",
            "Extracted text: \n",
            "\n",
            "0: 640x384 3 plates, 10.7ms\n",
            "Speed: 3.3ms preprocess, 10.7ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 384)\n",
            "Extracted text: 3066MP-4\n",
            "Extracted text: \n",
            "Extracted text: \n",
            "\n",
            "0: 640x384 2 plates, 13.6ms\n",
            "Speed: 3.6ms preprocess, 13.6ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 384)\n",
            "Extracted text: 3066MP-4\n",
            "Extracted text: \n",
            "\n",
            "0: 640x384 2 plates, 14.2ms\n",
            "Speed: 3.4ms preprocess, 14.2ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 384)\n",
            "Extracted text: 3066MP-4\n",
            "Extracted text: \n",
            "\n",
            "0: 640x384 1 plate, 12.5ms\n",
            "Speed: 4.1ms preprocess, 12.5ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 384)\n",
            "Extracted text: 3066MP-4\n",
            "\n",
            "0: 640x384 1 plate, 11.3ms\n",
            "Speed: 3.6ms preprocess, 11.3ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 384)\n",
            "Extracted text: 3066MP-4\n",
            "\n",
            "0: 640x384 2 plates, 13.5ms\n",
            "Speed: 3.6ms preprocess, 13.5ms inference, 2.2ms postprocess per image at shape (1, 3, 640, 384)\n",
            "Extracted text: 3066MP-4\n",
            "Extracted text: \n",
            "\n",
            "0: 640x384 2 plates, 16.3ms\n",
            "Speed: 3.5ms preprocess, 16.3ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 384)\n",
            "Extracted text: R066MP-4\n",
            "Extracted text: \n",
            "\n",
            "0: 640x384 2 plates, 10.7ms\n",
            "Speed: 3.5ms preprocess, 10.7ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 384)\n",
            "Extracted text: 3066MP-4\n",
            "Extracted text: \n",
            "\n",
            "0: 640x384 2 plates, 10.2ms\n",
            "Speed: 3.4ms preprocess, 10.2ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 384)\n",
            "Extracted text: 3066MP-4\n",
            "Extracted text: \n",
            "\n",
            "0: 640x384 2 plates, 13.6ms\n",
            "Speed: 3.6ms preprocess, 13.6ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 384)\n",
            "Extracted text: 3066MP-4\n",
            "Extracted text: \n",
            "\n",
            "0: 640x384 2 plates, 14.3ms\n",
            "Speed: 3.8ms preprocess, 14.3ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 384)\n",
            "Extracted text: 3066MP-4\n",
            "Extracted text: \n",
            "\n",
            "0: 640x384 2 plates, 11.3ms\n",
            "Speed: 3.5ms preprocess, 11.3ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 384)\n",
            "Extracted text: 3066MP-4\n",
            "Extracted text: \n",
            "\n",
            "0: 640x384 2 plates, 10.9ms\n",
            "Speed: 3.4ms preprocess, 10.9ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 384)\n",
            "Extracted text: 3066MP-4\n",
            "Extracted text: \n",
            "\n",
            "0: 640x384 2 plates, 13.3ms\n",
            "Speed: 3.3ms preprocess, 13.3ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 384)\n",
            "Extracted text: 3066MP-4\n",
            "Extracted text: \n",
            "\n",
            "0: 640x384 2 plates, 14.6ms\n",
            "Speed: 3.0ms preprocess, 14.6ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 384)\n",
            "Extracted text: 3066MP-4\n",
            "Extracted text: \n",
            "\n",
            "0: 640x384 2 plates, 12.6ms\n",
            "Speed: 3.4ms preprocess, 12.6ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 384)\n",
            "Extracted text: 3066MP-4\n",
            "Extracted text: \n",
            "\n",
            "0: 640x384 2 plates, 11.5ms\n",
            "Speed: 3.3ms preprocess, 11.5ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 384)\n",
            "Extracted text: 3066MP-4\n",
            "Extracted text: \n",
            "\n",
            "0: 640x384 3 plates, 13.8ms\n",
            "Speed: 3.7ms preprocess, 13.8ms inference, 2.2ms postprocess per image at shape (1, 3, 640, 384)\n",
            "Extracted text: BY 3066MP-4\n",
            "Extracted text: \n",
            "Extracted text: \n",
            "\n",
            "0: 640x384 3 plates, 14.5ms\n",
            "Speed: 3.4ms preprocess, 14.5ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 384)\n",
            "Extracted text: \n",
            "Extracted text: BY 3066MP-4\n",
            "Extracted text: \n",
            "\n",
            "0: 640x384 3 plates, 14.0ms\n",
            "Speed: 3.4ms preprocess, 14.0ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 384)\n",
            "Extracted text: BY 3066MP-4\n",
            "Extracted text: \n",
            "Extracted text: \n",
            "\n",
            "0: 640x384 3 plates, 13.5ms\n",
            "Speed: 3.5ms preprocess, 13.5ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 384)\n",
            "Extracted text: BY 3066MP-4\n",
            "Extracted text: EAPLR\n",
            "Extracted text: \n",
            "\n",
            "0: 640x384 3 plates, 13.6ms\n",
            "Speed: 3.8ms preprocess, 13.6ms inference, 3.4ms postprocess per image at shape (1, 3, 640, 384)\n",
            "Extracted text: BY 3066MP-4\n",
            "Extracted text: EAP L89\n",
            "Extracted text: \n",
            "\n",
            "0: 640x384 3 plates, 12.7ms\n",
            "Speed: 3.4ms preprocess, 12.7ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 384)\n",
            "Extracted text: BY 3066MP-4\n",
            "Extracted text: EAP 4895\n",
            "Extracted text: \n",
            "\n",
            "0: 640x384 3 plates, 14.0ms\n",
            "Speed: 3.2ms preprocess, 14.0ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 384)\n",
            "Extracted text: EAP 48953\n",
            "Extracted text: BY 3066MP-4\n",
            "Extracted text: \n",
            "\n",
            "0: 640x384 3 plates, 13.3ms\n",
            "Speed: 3.3ms preprocess, 13.3ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 384)\n",
            "Extracted text: BY 3066MP:-\n",
            "Extracted text: EAP 48953\n",
            "Extracted text: \n",
            "\n",
            "0: 640x384 3 plates, 13.7ms\n",
            "Speed: 3.5ms preprocess, 13.7ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 384)\n",
            "Extracted text: BY 3066MF\n",
            "Extracted text: EAP [8953\n",
            "Extracted text: \n",
            "\n",
            "0: 640x384 3 plates, 13.1ms\n",
            "Speed: 3.4ms preprocess, 13.1ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 384)\n",
            "Extracted text: BY 30661\n",
            "Extracted text: BAP L8953\n",
            "Extracted text: \n",
            "\n",
            "0: 640x384 3 plates, 13.6ms\n",
            "Speed: 3.5ms preprocess, 13.6ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 384)\n",
            "Extracted text: BY 306\n",
            "Extracted text: EAP L8953\n",
            "Extracted text: \n",
            "\n",
            "0: 640x384 3 plates, 13.6ms\n",
            "Speed: 3.6ms preprocess, 13.6ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 384)\n",
            "Extracted text: BY 3\n",
            "Extracted text: EAP L8s53\n",
            "Extracted text: \n",
            "\n",
            "0: 640x384 3 plates, 14.4ms\n",
            "Speed: 3.4ms preprocess, 14.4ms inference, 2.2ms postprocess per image at shape (1, 3, 640, 384)\n",
            "Extracted text: EAP L8955\n",
            "Extracted text: \n",
            "Extracted text: BY\n",
            "\n",
            "0: 640x384 2 plates, 16.1ms\n",
            "Speed: 3.3ms preprocess, 16.1ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 384)\n",
            "Extracted text: AP le95. 5\n",
            "Extracted text: \n",
            "\n",
            "0: 640x384 2 plates, 11.7ms\n",
            "Speed: 3.4ms preprocess, 11.7ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 384)\n",
            "Extracted text: EAP L895.5\n",
            "Extracted text: \n",
            "\n",
            "0: 640x384 2 plates, 10.7ms\n",
            "Speed: 3.3ms preprocess, 10.7ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 384)\n",
            "Extracted text: EAP 4895 5\n",
            "Extracted text: \n",
            "\n",
            "0: 640x384 2 plates, 13.3ms\n",
            "Speed: 3.5ms preprocess, 13.3ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 384)\n",
            "Extracted text: EAP 48955\n",
            "Extracted text: \n",
            "\n",
            "0: 640x384 2 plates, 13.0ms\n",
            "Speed: 3.4ms preprocess, 13.0ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 384)\n",
            "Extracted text: AP L895.5\n",
            "Extracted text: \n",
            "\n",
            "0: 640x384 1 plate, 13.7ms\n",
            "Speed: 3.3ms preprocess, 13.7ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 384)\n",
            "Extracted text: AP 48955\n",
            "\n",
            "0: 640x384 2 plates, 11.4ms\n",
            "Speed: 3.4ms preprocess, 11.4ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 384)\n",
            "Extracted text: EAP 4895.5\n",
            "Extracted text: \n",
            "\n",
            "0: 640x384 1 plate, 13.5ms\n",
            "Speed: 3.5ms preprocess, 13.5ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 384)\n",
            "Extracted text: EAP L895.5\n",
            "\n",
            "0: 640x384 1 plate, 12.6ms\n",
            "Speed: 4.2ms preprocess, 12.6ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 384)\n",
            "Extracted text: AP L8S5_5\n",
            "\n",
            "0: 640x384 1 plate, 11.7ms\n",
            "Speed: 3.3ms preprocess, 11.7ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 384)\n",
            "Extracted text: EAP Les5 5\n",
            "\n",
            "0: 640x384 2 plates, 13.8ms\n",
            "Speed: 3.1ms preprocess, 13.8ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 384)\n",
            "Extracted text: AP L8S5 5\n",
            "Extracted text: \n",
            "\n",
            "0: 640x384 2 plates, 14.3ms\n",
            "Speed: 4.4ms preprocess, 14.3ms inference, 2.2ms postprocess per image at shape (1, 3, 640, 384)\n",
            "Extracted text: AP L8s5 5\n",
            "Extracted text: \n",
            "\n",
            "0: 640x384 2 plates, 13.9ms\n",
            "Speed: 13.7ms preprocess, 13.9ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 384)\n",
            "Extracted text: EAP L895 5\n",
            "Extracted text: \n",
            "\n",
            "0: 640x384 2 plates, 13.2ms\n",
            "Speed: 3.4ms preprocess, 13.2ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 384)\n",
            "Extracted text: AP 4895.5\n",
            "Extracted text: \n",
            "\n",
            "0: 640x384 2 plates, 10.7ms\n",
            "Speed: 3.6ms preprocess, 10.7ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 384)\n",
            "Extracted text: AP L895-5\n",
            "Extracted text: \n",
            "\n",
            "0: 640x384 2 plates, 13.3ms\n",
            "Speed: 3.5ms preprocess, 13.3ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 384)\n",
            "Extracted text: AP L8s5-5\n",
            "Extracted text: \n",
            "\n",
            "0: 640x384 2 plates, 17.3ms\n",
            "Speed: 3.7ms preprocess, 17.3ms inference, 2.2ms postprocess per image at shape (1, 3, 640, 384)\n",
            "Extracted text: AP L8g5-5\n",
            "Extracted text: \n",
            "\n",
            "0: 640x384 2 plates, 17.8ms\n",
            "Speed: 3.6ms preprocess, 17.8ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 384)\n",
            "Extracted text: AP L8s5-5\n",
            "Extracted text: \n",
            "\n",
            "0: 640x384 1 plate, 46.0ms\n",
            "Speed: 9.7ms preprocess, 46.0ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 384)\n",
            "Extracted text: EAP L8ss5-5\n",
            "\n",
            "0: 640x384 1 plate, 53.2ms\n",
            "Speed: 6.6ms preprocess, 53.2ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 384)\n",
            "Extracted text: AP L8ss-5\n",
            "\n",
            "0: 640x384 1 plate, 32.8ms\n",
            "Speed: 4.3ms preprocess, 32.8ms inference, 2.7ms postprocess per image at shape (1, 3, 640, 384)\n",
            "Extracted text: AP 4895-5\n",
            "\n",
            "0: 640x384 1 plate, 15.9ms\n",
            "Speed: 3.3ms preprocess, 15.9ms inference, 2.2ms postprocess per image at shape (1, 3, 640, 384)\n",
            "Extracted text: EAP L895-5\n",
            "\n",
            "0: 640x384 1 plate, 40.8ms\n",
            "Speed: 3.6ms preprocess, 40.8ms inference, 5.1ms postprocess per image at shape (1, 3, 640, 384)\n",
            "Extracted text: AP 4895-5\n",
            "\n",
            "0: 640x384 1 plate, 16.5ms\n",
            "Speed: 4.2ms preprocess, 16.5ms inference, 2.5ms postprocess per image at shape (1, 3, 640, 384)\n",
            "Extracted text: AP L895.5\n",
            "\n",
            "0: 640x384 1 plate, 53.3ms\n",
            "Speed: 19.1ms preprocess, 53.3ms inference, 12.8ms postprocess per image at shape (1, 3, 640, 384)\n",
            "Extracted text: AP 4895-5\n",
            "\n",
            "0: 640x384 1 plate, 30.4ms\n",
            "Speed: 3.3ms preprocess, 30.4ms inference, 2.5ms postprocess per image at shape (1, 3, 640, 384)\n",
            "Extracted text: AP L8s5-5]\n",
            "\n",
            "0: 640x384 1 plate, 43.5ms\n",
            "Speed: 18.5ms preprocess, 43.5ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 384)\n",
            "Extracted text: AP L895-5\n",
            "\n",
            "0: 640x384 1 plate, 69.2ms\n",
            "Speed: 3.4ms preprocess, 69.2ms inference, 12.5ms postprocess per image at shape (1, 3, 640, 384)\n",
            "Extracted text: AP L8s5-5\n",
            "\n",
            "0: 640x384 1 plate, 32.9ms\n",
            "Speed: 3.5ms preprocess, 32.9ms inference, 18.5ms postprocess per image at shape (1, 3, 640, 384)\n",
            "Extracted text: AP L895 5\n",
            "\n",
            "0: 640x384 1 plate, 13.1ms\n",
            "Speed: 3.4ms preprocess, 13.1ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 384)\n",
            "Extracted text: AP 4895- 5\n",
            "\n",
            "0: 640x384 1 plate, 24.0ms\n",
            "Speed: 3.4ms preprocess, 24.0ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 384)\n",
            "Extracted text: APL895-5\n",
            "\n",
            "0: 640x384 1 plate, 27.4ms\n",
            "Speed: 3.5ms preprocess, 27.4ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 384)\n",
            "Extracted text: AP 4895-5\n",
            "\n",
            "0: 640x384 1 plate, 12.7ms\n",
            "Speed: 3.9ms preprocess, 12.7ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 384)\n",
            "Extracted text: AP L895-5\n",
            "\n",
            "0: 640x384 1 plate, 11.7ms\n",
            "Speed: 6.0ms preprocess, 11.7ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 384)\n",
            "Extracted text: AP4895-5\n",
            "\n",
            "0: 640x384 1 plate, 14.0ms\n",
            "Speed: 3.7ms preprocess, 14.0ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 384)\n",
            "Extracted text: AP 4895-5\n",
            "\n",
            "0: 640x384 1 plate, 18.6ms\n",
            "Speed: 12.5ms preprocess, 18.6ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 384)\n",
            "Extracted text: AP 4895-5\n",
            "\n",
            "0: 640x384 1 plate, 25.1ms\n",
            "Speed: 7.9ms preprocess, 25.1ms inference, 2.2ms postprocess per image at shape (1, 3, 640, 384)\n",
            "Extracted text: AP 4895-5\n",
            "\n",
            "0: 640x384 1 plate, 15.1ms\n",
            "Speed: 3.9ms preprocess, 15.1ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 384)\n",
            "Extracted text: AP 4895-5\n",
            "\n",
            "0: 640x384 1 plate, 11.8ms\n",
            "Speed: 6.6ms preprocess, 11.8ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 384)\n",
            "Extracted text: AP 4895-5\n",
            "\n",
            "0: 640x384 1 plate, 22.0ms\n",
            "Speed: 3.6ms preprocess, 22.0ms inference, 8.1ms postprocess per image at shape (1, 3, 640, 384)\n",
            "Extracted text: AP 4895-5\n",
            "\n",
            "0: 640x384 1 plate, 20.6ms\n",
            "Speed: 5.5ms preprocess, 20.6ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 384)\n",
            "Extracted text: AP L895-5\n",
            "\n",
            "0: 640x384 1 plate, 25.6ms\n",
            "Speed: 5.1ms preprocess, 25.6ms inference, 2.7ms postprocess per image at shape (1, 3, 640, 384)\n",
            "Extracted text: AP 4895-5\n",
            "\n",
            "0: 640x384 1 plate, 18.5ms\n",
            "Speed: 3.5ms preprocess, 18.5ms inference, 2.6ms postprocess per image at shape (1, 3, 640, 384)\n",
            "Extracted text: AP 4895- 5\n",
            "\n",
            "0: 640x384 1 plate, 32.1ms\n",
            "Speed: 3.5ms preprocess, 32.1ms inference, 2.8ms postprocess per image at shape (1, 3, 640, 384)\n",
            "Extracted text: AP 4895-5\n",
            "\n",
            "0: 640x384 1 plate, 24.3ms\n",
            "Speed: 4.1ms preprocess, 24.3ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 384)\n",
            "Extracted text: AP 4895-5\n",
            "\n",
            "0: 640x384 1 plate, 9.8ms\n",
            "Speed: 3.3ms preprocess, 9.8ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 384)\n",
            "Extracted text: AP 4895-5\n",
            "\n",
            "0: 640x384 1 plate, 13.9ms\n",
            "Speed: 3.8ms preprocess, 13.9ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 384)\n",
            "Extracted text: AP 4895-5\n",
            "\n",
            "0: 640x384 1 plate, 14.3ms\n",
            "Speed: 3.7ms preprocess, 14.3ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 384)\n",
            "Extracted text: AP L895-5\n",
            "\n",
            "0: 640x384 1 plate, 12.1ms\n",
            "Speed: 3.3ms preprocess, 12.1ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 384)\n",
            "Extracted text: AP 4895-5]\n",
            "\n",
            "0: 640x384 1 plate, 11.0ms\n",
            "Speed: 3.4ms preprocess, 11.0ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 384)\n",
            "Extracted text: AP 4895-5\n",
            "\n",
            "0: 640x384 1 plate, 14.2ms\n",
            "Speed: 3.6ms preprocess, 14.2ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 384)\n",
            "Extracted text: AP 4895-5\n",
            "\n",
            "0: 640x384 1 plate, 13.6ms\n",
            "Speed: 3.1ms preprocess, 13.6ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 384)\n",
            "Extracted text: AP 4895-5\n",
            "\n",
            "0: 640x384 1 plate, 12.3ms\n",
            "Speed: 3.5ms preprocess, 12.3ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 384)\n",
            "Extracted text: AP 4895-5\n",
            "\n",
            "0: 640x384 1 plate, 12.8ms\n",
            "Speed: 3.6ms preprocess, 12.8ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 384)\n",
            "Extracted text: AP 4895-35\n",
            "\n",
            "0: 640x384 1 plate, 11.6ms\n",
            "Speed: 3.5ms preprocess, 11.6ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 384)\n",
            "Extracted text: AP 4895-5\n",
            "\n",
            "0: 640x384 1 plate, 15.4ms\n",
            "Speed: 3.4ms preprocess, 15.4ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 384)\n",
            "Extracted text: AP 4895-5\n",
            "\n",
            "0: 640x384 1 plate, 14.6ms\n",
            "Speed: 3.6ms preprocess, 14.6ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 384)\n",
            "Extracted text: AP 4895-5\n",
            "\n",
            "0: 640x384 1 plate, 13.6ms\n",
            "Speed: 3.4ms preprocess, 13.6ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 384)\n",
            "Extracted text: AP 4895-5\n",
            "\n",
            "0: 640x384 1 plate, 11.4ms\n",
            "Speed: 3.5ms preprocess, 11.4ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 384)\n",
            "Extracted text: AP 4895-5\n",
            "\n",
            "0: 640x384 1 plate, 21.4ms\n",
            "Speed: 3.5ms preprocess, 21.4ms inference, 3.5ms postprocess per image at shape (1, 3, 640, 384)\n",
            "Extracted text: AP 4895-5\n",
            "\n",
            "0: 640x384 1 plate, 15.5ms\n",
            "Speed: 5.6ms preprocess, 15.5ms inference, 2.2ms postprocess per image at shape (1, 3, 640, 384)\n",
            "Extracted text: AP 4895-5\n",
            "\n",
            "0: 640x384 1 plate, 15.7ms\n",
            "Speed: 3.5ms preprocess, 15.7ms inference, 2.5ms postprocess per image at shape (1, 3, 640, 384)\n",
            "Extracted text: AP 4895-5]\n",
            "\n",
            "0: 640x384 1 plate, 19.2ms\n",
            "Speed: 3.7ms preprocess, 19.2ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 384)\n",
            "Extracted text: AP 4895-5]\n",
            "\n",
            "0: 640x384 1 plate, 43.0ms\n",
            "Speed: 3.5ms preprocess, 43.0ms inference, 2.6ms postprocess per image at shape (1, 3, 640, 384)\n",
            "Extracted text: AP 4895-5\n",
            "\n",
            "0: 640x384 1 plate, 55.8ms\n",
            "Speed: 9.3ms preprocess, 55.8ms inference, 2.6ms postprocess per image at shape (1, 3, 640, 384)\n",
            "Extracted text: AP 4895-5\n",
            "\n",
            "0: 640x384 1 plate, 24.9ms\n",
            "Speed: 10.5ms preprocess, 24.9ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 384)\n",
            "Extracted text: AP 4895-5\n",
            "\n",
            "0: 640x384 1 plate, 22.1ms\n",
            "Speed: 3.2ms preprocess, 22.1ms inference, 5.0ms postprocess per image at shape (1, 3, 640, 384)\n",
            "Extracted text: AP 4895-5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1X_dfSSH3ex5"
      },
      "source": [
        "<img align=\"left\" src=\"https://github.com/user-attachments/assets/d9f5efe7-d058-48f4-9515-f7ccf6084c2f\" height=\"640\">"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Instead of video capture, read the image"
      ],
      "metadata": {
        "id": "GpdKzrNOWOw3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "P-Nv5kpCWVPa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's say your photo is named my_car_photo.jpg and you uploaded it to Colab.\n",
        "\n",
        "1. Upload my_car_photo.jpg.\n",
        "\n",
        "2. Modify the code cell for reading the input:"
      ],
      "metadata": {
        "id": "JXYH8vRZWWin"
      }
    },
    {
      "source": [
        "# Instead of video capture, read the image\n",
        "im0 = cv2.imread(\"/content/my_car_photo.jpg\")\n",
        "assert im0 is not None, \"Error reading image file\"\n",
        "\n",
        "# You don't need video_writer for an image\n",
        "# video_writer = cv2.VideoWriter(...)"
      ],
      "cell_type": "code",
      "metadata": {
        "id": "Gg_xAa1lWT2j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "3. Modify the processing cell:"
      ],
      "metadata": {
        "id": "Novp25RkWZsn"
      }
    },
    {
      "source": [
        "# Remove the while loop\n",
        "# while cap.isOpened():\n",
        "#     success, im0 = cap.read()\n",
        "#     if not success:\n",
        "#         break\n",
        "\n",
        "# Initialize Annotator for the image\n",
        "ann = Annotator(im0, line_width=3)\n",
        "\n",
        "results = model.predict(im0)[0].boxes\n",
        "boxes = results.xyxy.cpu()\n",
        "clss = results.cls.cpu()\n",
        "\n",
        "for cls, box in zip(clss, boxes):\n",
        "    height, width, _ = im0.shape\n",
        "\n",
        "    # Calculate padded coordinates\n",
        "    x1 = max(int(box[0]) - padding, 0)\n",
        "    y1 = max(int(box[1]) - padding, 0)\n",
        "    x2 = min(int(box[2]) + padding, width)\n",
        "    y2 = min(int(box[3]) + padding, height)\n",
        "\n",
        "    # Crop the object with padding\n",
        "    if y2 > y1 and x2 > x1:\n",
        "        cropped_im = im0[y1:y2, x1:x2]\n",
        "\n",
        "        # Use EasyOCR to read text from the cropped image\n",
        "        results_easyocr = reader.readtext(cropped_im)\n",
        "\n",
        "        # Extract the recognized text\n",
        "        recognized_text = \"\"\n",
        "        for result in results_easyocr:\n",
        "            recognized_text += result[1] + \" \"\n",
        "\n",
        "        print(f\"Extracted text: {recognized_text.strip()}\")\n",
        "\n",
        "        ann.box_label(box, label=str(recognized_text.strip()), color=colors(cls, True))\n",
        "    else:\n",
        "        print(f\"Invalid crop region for box: {box}\")\n",
        "        recognized_text = \"N/A\"\n",
        "\n",
        "        ann.box_label(box, label=recognized_text, color=colors(cls, True))\n",
        "\n",
        "# Display or save the annotated image\n",
        "# For displaying in Colab:\n",
        "from google.colab.patches import cv2_imshow\n",
        "# cv2_imshow(im0)\n",
        "\n",
        "# For saving the image:\n",
        "cv2.imwrite(\"annotated_car_photo.jpg\", im0)\n",
        "\n",
        "# You don't need to release cap or video_writer for an image\n",
        "# cap.release()\n",
        "# video_writer.release()"
      ],
      "cell_type": "code",
      "metadata": {
        "id": "Z2_zas67WioD"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}